use std::{
    collections::{HashMap, HashSet},
    vec::Vec,
};

fn is_descriptor(c: char) -> bool {
    c as u32 >= 0x2FF0 && c as u32 <= 0x2FFB
}
fn is_ascii(c: char) -> bool {
    c as u32 <= 0xFF
}

type Mapping = HashMap<char, HashSet<char>>;

pub struct ServerData {
    pub char_to_comp: Mapping,
    pub comp_to_char: Mapping,
    pub char_to_first_comp: HashMap<char, Vec<char>>,
    pub kanjidicplus: HashSet<char>,
    pub media: HashSet<char>,
    pub joyoplus: HashSet<char>,
    pub char_to_strokes: HashMap<char, u64>,
    pub radical_to_char: HashMap<char, char>,
    pub common_comps: Vec<char>,
}

pub struct SearchArgs<'a> {
    pub reverse: bool,
    pub simple: bool,
    pub lite: bool,
    pub filter_level: FilterLevel,
    pub input: Option<&'a str>,
    pub lookup: Option<&'a str>,
}

#[repr(u8)]
pub enum FilterLevel {
    JoyoPlus = 0,
    Media = 1,
    KanjiDicPlus = 2,
    All = 3,
}

impl ServerData {
    pub fn radical_text(&self) -> String {
        let mut radical_text = "".to_string();
        let mut last_strokes = 0;
        for c in &self.common_comps {
            let strokes = self.get_strokes(*c);
            if strokes != last_strokes {
                if last_strokes != 0 {
                    radical_text += "\n";
                }
                radical_text.push_str(&format!("{} strokes ï¼š", strokes));
                last_strokes = strokes;
            }
            radical_text += &format!("{} ", c);
        }
        radical_text
    }
    pub fn search(&self, args: SearchArgs) -> String {
        let reverse = args.reverse;
        let simple = args.simple;
        let filter_level = args.filter_level as u8;

        let mut input = args.input;
        if input.is_none() {
            input = args.lookup;
        }

        if let Some(input) = input {
            let lookup_output = if reverse {
                ServerData::chars_to_components
            } else {
                ServerData::components_to_chars
            }(
                self,
                &mut HashSet::<char>::new(),
                &input
                    .chars()
                    .map(|c| *self.radical_to_char.get(&c).unwrap_or(&c))
                    .collect::<HashSet<char>>(),
                !simple,
            );

            let filter_function = |c| {
                if filter_level == 0 {
                    self.joyoplus.contains(&c)
                } else if filter_level == 1 {
                    self.media.contains(&c)
                } else if filter_level == 2 {
                    self.kanjidicplus.contains(&c)
                } else {
                    true
                }
            };

            let mut lookup_vec = lookup_output
                .into_iter()
                .filter(|c| if !reverse { filter_function(*c) } else { true })
                .collect::<Vec<char>>();

            lookup_vec.sort();

            let mut stroke_mapping = HashMap::<u64, Vec<char>>::new();
            let mut stroke_counts = Vec::<u64>::new();
            for c in lookup_vec {
                let count = self.get_strokes(c);
                if !stroke_mapping.contains_key(&count) {
                    stroke_mapping.insert(count, Vec::<char>::new());
                    stroke_counts.push(count);
                }
                stroke_mapping.get_mut(&count).unwrap().push(c);
            }
            stroke_counts.sort();
            let mut output_list_html = "".to_string();
            if stroke_counts.len() > 0 {
                for count in stroke_counts {
                    output_list_html += &format!("{} strokesï¼š", count);
                    for c in stroke_mapping.get(&count).unwrap() {
                        output_list_html.push(*c);
                    }
                    output_list_html += &"\n";
                }
            } else {
                output_list_html += &"(no matches)";
            }

            if args.lite {
                return output_list_html;
            }
        } else {
            if args.lite {
                return "".to_string();
            }
        }
        unimplemented!()
    }

    fn chars_to_components(
        &self,
        seen: &mut HashSet<char>,
        set: &HashSet<char>,
        isrecursive: bool,
    ) -> HashSet<char> {
        let mut new = HashSet::<char>::new();

        for c in set {
            if let Some(comps) = self.char_to_comp.get(c) {
                new = new.union(comps).cloned().collect();
            }
        }

        new = new.difference(seen).cloned().collect();
        for c in &new {
            seen.insert(*c);
        }

        if isrecursive && new.len() > 0 {
            new = new
                .union(&self.chars_to_components(seen, &new, isrecursive))
                .cloned()
                .collect();
        }

        new
    }

    fn component_to_chars(
        &self,
        seen: &mut HashSet<char>,
        in_c: char,
        isrecursive: bool,
    ) -> HashSet<char> {
        let mut new = HashSet::<char>::new();

        if let Some(chars) = self.comp_to_char.get(&in_c) {
            new = chars.clone();
        }

        new = new.difference(seen).cloned().collect();
        for c in &new {
            seen.insert(*c);
        }

        if isrecursive && new.len() > 0 {
            for c in new.clone() {
                for c2 in self.component_to_chars(seen, c, isrecursive) {
                    new.insert(c2);
                }
            }
        }

        new
    }

    fn components_to_chars(
        &self,
        seen: &mut HashSet<char>,
        set: &HashSet<char>,
        isrecursive: bool,
    ) -> HashSet<char> {
        let mut new = HashSet::<char>::new();
        let mut first = true;

        for c in set {
            if first {
                new = self.component_to_chars(&mut seen.clone(), *c, isrecursive);
            } else {
                new = new
                    .intersection(&self.component_to_chars(&mut seen.clone(), *c, isrecursive))
                    .cloned()
                    .collect();
            }
            first = false;
        }

        new
    }

    // TODO: interpret â‘¡ etc.
    fn get_strokes(&self, c: char) -> u64 {
        if c == 'è¾¶' {
            return 4;
        }
        if c == 'ä’‘' {
            return 3;
        }
        if c == 'é¾·' {
            return 4;
        }
        if c == 'é˜' {
            return 3;
        }
        if c == 'å…' {
            8
        } else if let Some(stroke_count) = self.char_to_strokes.get(&c) {
            *stroke_count
        } else if let Some(set) = self.char_to_first_comp.get(&c) {
            set.iter().map(|c2| self.get_strokes(*c2)).sum()
        } else {
            match c {
                'â‘ ' => 1,
                'â‘¡' => 2,
                'â‘¢' => 3,
                'â‘£' => 4,
                'â‘¤' => 5,
                'â‘¥' => 6,
                'â‘¦' => 7,
                'â‘§' => 8,
                'â‘¨' => 9,
                'â‘©' => 10,
                'â‘ª' => 11,
                'â‘«' => 12,
                'â‘¬' => 13,
                'â‘­' => 14,
                'â‘®' => 15,
                'â‘¯' => 16,
                'â‘°' => 17,
                'â‘±' => 18,
                'â‘²' => 19,
                'â‘³' => 20,

                'ï©' => 4,
                'âº†' => 2,
                'ï©‚' => 11,
                'ï©›' => 9,
                'ğ­•„' => 3,
                'ï¨µ' => 8,
                'ã‚µ' => 3,
                'ã‚³' => 2,
                'ã‡‡' => 1,
                'âº„' => 1,
                'ã‚ˆ' => 2,
                'âºŒ' => 3,
                'âºŠ' => 2,
                'ã„' => 2,
                'ã‚¹' => 2,
                'ã‚Š' => 2,
                'ãƒ¦' => 2,
                'ã‡Œ' => 1, // should be 2 but is only actually used for composition in a single character where it has one stroke
                'ã‡‰' => 1,
                'ã‡€' => 1,
                'ã‡“' => 1,
                'ğ›‚¦' => 2,
                'ğ®Œ' => 5,
                'ğ­£”' => 5,
                'ğ® •' => 8,
                'ğ¬º»' => 5,

                'â»Œ' => 3,
                'è¾¶' => 4,
                _ => {
                    println!("character {} has no stroke count", c);
                    0
                }
            }
        }
    }
}

fn ids_lines_to_mappings(
    lines: &Vec<String>,
    rewrites: &HashMap<char, char>,
) -> (
    Mapping,
    Mapping,
    HashMap<char, Vec<char>>,
    HashMap<char, u64>,
) {
    let mut char_to_comp = Mapping::new();
    let mut comp_to_char = Mapping::new();
    let mut char_to_first_comp = HashMap::new();
    let mut comp_frequencies = HashMap::new();
    for line in lines {
        let priority_exists = line.contains('J');
        let mut tokens: Vec<String> = line.split('\t').map(|x| x.to_string()).collect();
        if tokens.len() < 3 {
            continue;
        }
        tokens.remove(0);
        let kanji_chars: Vec<char> = tokens
            .remove(0)
            .chars()
            .map(|c| *rewrites.get(&c).unwrap_or(&c))
            .collect();
        assert!(kanji_chars.len() == 1);
        let kanji = kanji_chars[0];
        let mut first = true;
        for token in tokens {
            if priority_exists && !token.contains('J') {
                continue;
            }
            for c in token.chars().map(|c| *rewrites.get(&c).unwrap_or(&c)) {
                if c == kanji || is_descriptor(c) || is_ascii(c) {
                    continue;
                }

                if !char_to_comp.contains_key(&kanji) {
                    char_to_comp.insert(kanji, HashSet::<char>::new());
                }
                char_to_comp.get_mut(&kanji).unwrap().insert(c);

                if first {
                    *comp_frequencies.entry(c).or_insert(0) += 1;
                }

                if first && !char_to_first_comp.contains_key(&kanji) {
                    char_to_first_comp.insert(kanji, Vec::<char>::new());
                }
                char_to_first_comp.get_mut(&kanji).unwrap().push(c);

                if !comp_to_char.contains_key(&c) {
                    comp_to_char.insert(c, HashSet::<char>::new());
                }
                comp_to_char.get_mut(&c).unwrap().insert(kanji);
            }
            first = false;
        }
    }

    (
        char_to_comp,
        comp_to_char,
        char_to_first_comp,
        comp_frequencies,
    )
}

fn build_stroke_count_mapping(
    unicode_lines: &Vec<String>,
    joyo_lines: &Vec<String>,
) -> HashMap<char, u64> {
    let mut stroke_counts = HashMap::<char, u64>::new();
    for line in unicode_lines {
        let mut tokens: Vec<String> = line.split('\t').map(|x| x.to_string()).collect();
        if tokens.len() < 3 {
            continue;
        }
        let kanji_codepoint = tokens.remove(0);
        let info_type = tokens.remove(0); // kTotalStrokes
        if info_type != "kTotalStrokes" {
            continue;
        }
        assert!(kanji_codepoint.starts_with("U+"));
        assert!(kanji_codepoint.len() == 6 || kanji_codepoint.len() == 7); // U+XXXX or U+XXXXX format
                                                                           //println!("`{}`", &kanji_codepoint[2..]);
        let kanji =
            std::char::from_u32(u32::from_str_radix(&kanji_codepoint[2..], 16).unwrap()).unwrap();
        let stroke_count_text = tokens
            .remove(0)
            .split(' ')
            .map(|x| x.to_string())
            .next()
            .unwrap();
        let stroke_count = stroke_count_text.parse::<u64>().unwrap();
        stroke_counts.insert(kanji, stroke_count);
    }
    for line in joyo_lines {
        let tokens: Vec<String> = line.split('\t').map(|x| x.to_string()).collect();
        if tokens.len() < 4 {
            continue;
        }
        let kanji = tokens[0].chars().next().unwrap();
        let stroke_count = tokens[3].parse().unwrap();
        stroke_counts.insert(kanji, stroke_count);
    }

    stroke_counts
}
fn build_radical_character_conversion(lines: &Vec<String>) -> HashMap<char, char> {
    let mut mapping = HashMap::<char, char>::new();
    for line in lines {
        let line = line.split('#').next().unwrap();
        let mut tokens: Vec<String> = line.split(';').map(|x| x.trim().to_string()).collect();
        if tokens.len() < 2 {
            continue;
        }
        let dest = tokens.remove(1);
        let kanji = std::char::from_u32(u32::from_str_radix(&dest, 16).unwrap()).unwrap();
        let source = tokens.remove(0);
        if !source.contains("..") {
            let radical = std::char::from_u32(u32::from_str_radix(&source, 16).unwrap()).unwrap();
            mapping.insert(radical, kanji);
        } else {
            let parts = source.split("..").collect::<Vec<_>>();
            for i in u32::from_str_radix(parts[0], 16).unwrap()
                ..=u32::from_str_radix(parts[1], 16).unwrap()
            {
                let c = std::char::from_u32(i).unwrap();
                mapping.insert(c, kanji);
            }
        }
    }
    mapping.insert('â»Œ', 'è¾¶');
    mapping.insert('â»', 'é˜');
    mapping.insert('â»–', 'é˜');

    mapping
}

fn is_non_radical_search_component(c: &char) -> bool {
    "â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³çºŸé—¨é¥£é©¬è´è½¦é’…é¸Ÿé¡µé•¸è® é±¼".contains(*c)
}

pub fn init() -> std::io::Result<ServerData> {
    let ids = include_str!("../ids.txt"); // https://github.com/cjkvi/cjkvi-ids/blob/master/ids.txt
    let kanjidicplus_kanji = include_str!("../kanjidic2_kanji_plus.txt");
    let media_kanji = include_str!("../common.txt");
    let joyoplus_kanji = include_str!("../joyoplus2.txt");
    let unihan_dict_data = include_str!("../Unihan_DictionaryLikeData.txt");
    let unihan_rad_data = include_str!("../EquivalentUnifiedIdeograph.txt");

    let radical_to_char = build_radical_character_conversion(
        &unihan_rad_data
            .lines()
            .map(|x| x.to_string())
            .collect::<Vec<_>>(),
    );

    let ids_lines: Vec<String> = ids.lines().map(|x| x.to_string()).collect();
    let (char_to_comp, comp_to_char, char_to_first_comp, mut comp_frequencies) =
        ids_lines_to_mappings(&ids_lines, &radical_to_char);

    let joyo_lines: Vec<String> = unihan_dict_data.lines().map(|x| x.to_string()).collect();
    let stroke_lines: Vec<String> = unihan_dict_data
        .lines()
        .filter(|x| x.starts_with("U+"))
        .map(|x| x.to_string())
        .collect();
    let char_to_strokes = build_stroke_count_mapping(&stroke_lines, &joyo_lines);

    let mut data = ServerData {
        char_to_comp,
        comp_to_char,
        char_to_first_comp,
        kanjidicplus: kanjidicplus_kanji.chars().collect(),
        media: media_kanji.chars().collect(),
        joyoplus: joyoplus_kanji.chars().collect(),
        char_to_strokes,
        radical_to_char,
        common_comps: Vec::new(),
    };

    let mut common_comps = comp_frequencies
        .drain()
        .filter(|(a, _)| !is_non_radical_search_component(a))
        .collect::<Vec<_>>();
    common_comps.sort_unstable_by(|a, b| a.0.cmp(&b.0));
    common_comps.sort_by(|a, b| b.1.cmp(&a.1));
    common_comps.truncate(300);
    let mut common_comps = common_comps.drain(..).collect::<HashMap<_, _>>();
    // radicals used by jisho
    for mut c in "ä¸€ï½œä¸¶ãƒä¹™äº…äºŒäº äººâº…ğ †¢å„¿å…¥ãƒä¸·å†‚å†–å†«å‡ å‡µåˆ€âº‰åŠ›å‹¹åŒ•åŒšååœå©å‚å¶åˆãƒä¹ãƒ¦ä¹ƒğ ‚‰â»Œå£å›—åœŸå£«å¤‚å¤•å¤§å¥³å­å®€å¯¸å°âºŒå°¢å°¸å±®å±±å·å·›å·¥å·²å·¾å¹²å¹ºå¹¿å»´å»¾å¼‹å¼“ãƒ¨å½‘å½¡å½³âº–âº˜âº¡âº¨âº¾â»â»–ä¹Ÿäº¡åŠä¹…âº¹å¿ƒæˆˆæˆ¸æ‰‹æ”¯æ”µæ–‡æ–—æ–¤æ–¹æ— æ—¥æ›°æœˆæœ¨æ¬ æ­¢æ­¹æ®³æ¯”æ¯›æ°æ°”æ°´ç«âº£çˆªçˆ¶çˆ»çˆ¿ç‰‡ç‰›çŠ¬âº­ç‹å…ƒäº•å‹¿å°¤äº”å±¯å·´æ¯‹ç„ç“¦ç”˜ç”Ÿç”¨ç”°ç–‹ç–’ç™¶ç™½çš®çš¿ç›®çŸ›çŸ¢çŸ³ç¤ºç¦¸ç¦¾ç©´ç«‹â»‚ä¸–å·¨å†Šæ¯âº²ç‰™ç“œç«¹ç±³ç³¸ç¼¶ç¾Šç¾½è€Œè€’è€³è¿è‚‰è‡ªè‡³è‡¼èˆŒèˆŸè‰®è‰²è™è™«è¡€è¡Œè¡£è¥¿è‡£è¦‹è§’è¨€è°·è±†è±•è±¸è²èµ¤èµ°è¶³èº«è»Šè¾›è¾°é…‰é‡†é‡Œèˆ›éº¦é‡‘é•·é–€éš¶éš¹é›¨é’éå¥„å²¡å…æ–‰é¢é©éŸ­éŸ³é é¢¨é£›é£Ÿé¦–é¦™å“é¦¬éª¨é«˜é«Ÿé¬¥é¬¯é¬²é¬¼ç«œéŸ‹é­šé³¥é¹µé¹¿éº»äº€å•‡é»„é»’é»é»¹ç„¡æ­¯é»½é¼é¼“é¼ é¼»é½Šé¾ ".chars()
    {
        c = *data.radical_to_char.get(&c).unwrap_or(&c);
        if data.comp_to_char.contains_key(&c)
        {
            common_comps.insert(c, 0);
        }
    }
    // components of common components
    for mut c in "ç”µå£´ä¸šã¡€æ°ºé•¸å†‹å³¶çƒç”¶è€‚é¾¶å…ğ§°¨ä¹ ä¸ƒã„è‚€ğ ‚‡äºˆå†…å¤®".chars()
    // ğ ‚­ğ «”
    {
        c = *data.radical_to_char.get(&c).unwrap_or(&c);
        if data.comp_to_char.contains_key(&c) {
            common_comps.insert(c, 0);
        }
    }
    common_comps.insert('â»Œ', 0);
    let mut common_comps = common_comps.drain().collect::<Vec<_>>();
    common_comps.sort_unstable_by(|a, b| a.0.cmp(&b.0));
    common_comps.sort_by(|a, b| data.get_strokes(a.0).cmp(&data.get_strokes(b.0)));
    data.common_comps = common_comps.drain(..).map(|x| x.0).collect::<_>();

    Ok(data)
}
